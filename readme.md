# ğŸš€ Weather data pipeline 

## ğŸ“Œ Objectif
Ce projet automatise la migration et lâ€™intÃ©gration de donnÃ©es mÃ©tÃ©o provenant de plusieurs sources (JSON, Excel) vers une base **MongoDB Replica Set** hÃ©bergÃ©e sur AWS ECS.  
Les donnÃ©es sont normalisÃ©es, converties dans les bonnes unitÃ©s et validÃ©es via des tests automatisÃ©s.

---

## ğŸ› ï¸ Stack technique
- **Python 3.12** (pandas, pymongo, boto3, pytest)
- **MongoDB Replica Set** (dÃ©ployÃ© sur ECS/EC2)
- **AWS S3** (stockage des fichiers sources)
- **Airbyte** (ingestion des donnÃ©es vers S3)
- **Docker** (containerisation)
- **ECS Task Definition** (migration automatisÃ©e)
- **Pytest** (validation post-migration)

---

## ğŸ“‚ Structure du repo

```
.
â”œâ”€â”€ migration/
â”‚   â”œâ”€â”€ Dockerfile            # Image de migration
â”‚   â”œâ”€â”€ migration.py          # Script principal (orchestrateur)
â”‚   â”œâ”€â”€ scriptjson.py         # Ingestion JSON depuis S3 (InfoClimat)
â”‚   â”œâ”€â”€ scriptxls1.py         # Ingestion XLS (Ichtegem, BE)
â”‚   â”œâ”€â”€ scriptxls2.py         # Ingestion XLS (La Madeleine, FR)
â”‚   â””â”€â”€ test_migration.py     # Tests Pytest (validation MongoDB)
â””â”€â”€ infra/
    â”œâ”€â”€ mongo1-task.json
    â”œâ”€â”€ mongo2-task.json
    â”œâ”€â”€ mongo-arbiter-task.json
    â””â”€â”€ migration-task.json
```

---

## ğŸŒ Sources de donnÃ©es (via Airbyte + S3)

Les donnÃ©es mÃ©tÃ©o proviennent de **trois sources distinctes** collectÃ©es avec **Airbyte** et stockÃ©es dans un bucket **AWS S3** :

1. **Infoclimat (JSON)**  
   [Data_Source1_011024-071024.json](https://s3.eu-west-1.amazonaws.com/course.oc-static.com/projects/922_Data+Engineer/922_P8/Data_Source1_011024-071024.json)

2. **Weather Underground â€“ Ichtegem, BE (Excel)**  
   [Weather Underground - Ichtegem, BE.xlsx](https://s3.eu-west-1.amazonaws.com/course.oc-static.com/projects/922_Data+Engineer/922_P8/Weather+Underground+-+Ichtegem%2C+BE.xlsx)

3. **Weather Underground â€“ La Madeleine, FR (Excel)**  
   [Weather Underground - La Madeleine, FR.xlsx](https://s3.eu-west-1.amazonaws.com/course.oc-static.com/projects/922_Data+Engineer/922_P8/Weather+Underground+-+La+Madeleine%2C+FR.xlsx)

---

## âš™ï¸ Mise en place avec Airbyte

### 1. Installer Airbyte (Docker)
```bash
git clone https://github.com/airbytehq/airbyte.git
cd airbyte
./run-ab-platform.sh
```
Airbyte est ensuite disponible sur [http://localhost:8000](http://localhost:8000).

---

### 2. CrÃ©er les **connecteurs source**
Dans lâ€™interface Airbyte :
- Source **HTTP/CSV/JSON** â†’ pour le fichier JSON Infoclimat  
- Source **HTTP/Excel** â†’ pour le fichier XLS dâ€™Ichtegem  
- Source **HTTP/Excel** â†’ pour le fichier XLS de La Madeleine  
ğŸ‘‰ Utiliser directement les URLs ci-dessus comme endpoints.

---

### 3. CrÃ©er une **destination S3**
- Type : **Amazon S3**  
- Bucket : `weather-data-pipeline`  
- Format de sortie : `CSV` ou `Parquet` (ici `CSV`)  
- Dossiers cibles :  
  - `/infoclimat/`  
  - `/ichtegem/`  
  - `/lamadeleine/`

---

### 4. Synchroniser les donnÃ©es
Lancer une **Sync** dans Airbyte et vÃ©rifier que les fichiers apparaissent bien dans S3 :  
```
s3://weather-data-pipeline/infoclimat/
s3://weather-data-pipeline/ichtegem/
s3://weather-data-pipeline/lamadeleine/
```

---

### 5. Lancer la migration
Une fois les donnÃ©es prÃ©sentes dans S3, exÃ©cutez la **Migration Task ECS** (voir section DÃ©ploiement ECS) qui :  
- TÃ©lÃ©charge les fichiers depuis S3  
- Nettoie et transforme les donnÃ©es  
- InsÃ¨re dans MongoDB  
- Valide avec Pytest  

---

## ğŸ”§ PrÃ©-requis

Avant de dÃ©ployer sur AWS, assurez-vous dâ€™avoir installÃ© et configurÃ© :

1. **AWS CLI v2**
   - Installation : https://docs.aws.amazon.com/cli/latest/userguide/getting-started-install.html
   - VÃ©rification :
     ```bash
     aws --version
     ```

2. **Configuration des credentials**
   - Soit via `aws configure` :
     ```bash
     aws configure
     ```
     (renseignez **AWS Access Key**, **Secret Key**, **region** et **output format**)
   - Soit via des variables dâ€™environnement :
     ```bash
     export AWS_ACCESS_KEY_ID=...
     export AWS_SECRET_ACCESS_KEY=...
     export AWS_DEFAULT_REGION=eu-west-3
     ```

3. **Docker** (pour builder et tester vos images localement)
   - VÃ©rifiez avec :
     ```bash
     docker --version
     ```

4. **Python 3.12 + pip** (pour exÃ©cuter localement les scripts et tests si besoin)

---

## ğŸ” Contenu et rÃ´le de lâ€™image `migration`

Lâ€™image Docker `lyut78/migration:latest` embarque lâ€™ensemble des scripts nÃ©cessaires pour migrer et valider les donnÃ©es mÃ©tÃ©o.  
Elle est orchestrÃ©e par le script `migration.py`, qui exÃ©cute les Ã©tapes suivantes :

1. **VÃ©rification de la collection MongoDB**
   - Si la collection `weather` est vide â†’ dÃ©clenche la migration.
   - Sinon â†’ aucun traitement nâ€™est lancÃ©.

2. **ExÃ©cution des scripts de migration**
   - `scriptjson.py`  
     - TÃ©lÃ©charge depuis S3 le fichier JSON Infoclimat  
     - Normalise et nettoie les donnÃ©es (types, NaN â†’ None, conversion en datetime ISO)  
     - Sauvegarde un pickle `df_json.pkl`  
     - InsÃ¨re les donnÃ©es dans MongoDB  

   - `scriptxls1.py`  
     - TÃ©lÃ©charge depuis S3 le fichier Excel (Ichtegem, BE)  
     - Nettoie et convertit les unitÃ©s (Â°F â†’ Â°C, mph â†’ km/h, in â†’ mm)  
     - Ajoute les mÃ©tadonnÃ©es station (id, latitude, longitude, etc.)  
     - Sauvegarde un pickle `df_xls1.pkl`  
     - InsÃ¨re dans MongoDB  

   - `scriptxls2.py`  
     - MÃªme logique que `scriptxls1.py` mais pour la station La Madeleine (FR).  
     - GÃ©nÃ¨re le fichier `df_xls2.pkl`  
     - InsÃ¨re dans MongoDB  

3. **Tests automatiques**
   - Lancement de `pytest test_migration.py`  
   - VÃ©rifie que :  
     - Les colonnes insÃ©rÃ©es dans MongoDB correspondent exactement au schÃ©ma attendu  
     - Le nombre de documents insÃ©rÃ©s correspond au nombre de lignes des DataFrames pickle  

4. **Nettoyage**
   - Suppression automatique des fichiers temporaires `.pkl` aprÃ¨s validation.

ğŸ‘‰ Lâ€™image `migration` sert donc de **job one-shot** Ã  exÃ©cuter sur ECS :  
elle importe les donnÃ©es depuis S3, les transforme, les charge dans MongoDB et valide leur qualitÃ©.

---

## â˜ï¸ DÃ©ploiement MongoDB Replica Set + Migration sur AWS ECS

Le projet est conÃ§u pour tourner sur **ECS/EC2** avec un Replica Set MongoDB.  
Quatre Task Definitions sont fournies dans `infra/` :

- `mongo1-task.json` â†’ premier nÅ“ud MongoDB
- `mongo2-task.json` â†’ second nÅ“ud MongoDB
- `mongo-arbiter-task.json` â†’ arbitre pour le quorum du Replica Set
- `migration-task.json` â†’ exÃ©cute la migration et les tests

---

### 1. Enregistrer les Task Definitions
```bash
aws ecs register-task-definition --cli-input-json file://infra/mongo1-task.json
aws ecs register-task-definition --cli-input-json file://infra/mongo2-task.json
aws ecs register-task-definition --cli-input-json file://infra/mongo-arbiter-task.json
aws ecs register-task-definition --cli-input-json file://infra/migration-task.json
```

---

### 2. Lancer les containers MongoDB
```bash
aws ecs run-task --cluster my-cluster --task-definition mongo1-task --launch-type EC2
aws ecs run-task --cluster my-cluster --task-definition mongo2-task --launch-type EC2
aws ecs run-task --cluster my-cluster --task-definition mongo-arbiter-task --launch-type EC2
```

âš ï¸ VÃ©rifiez que chaque tÃ¢che a une IP dans le VPC et que le security group ouvre le port **27017/27018**.

---

### 3. Initialiser le Replica Set
Une fois les trois containers lancÃ©s, connectez-vous Ã  `mongo1` et initialisez le Replica Set :

```bash
docker exec -it <mongo1-container-id> mongosh
```

Puis dans la console Mongo :
```javascript
rs.initiate({
  _id: "rs0",
  members: [
    { _id: 0, host: "mongo1.mongo.local:27017" },
    { _id: 1, host: "mongo2.mongo.local:27017" },
    { _id: 2, host: "mongo-arbiter.mongo.local:27018", arbiterOnly: true }
  ]
})
```

---

### 4. Lancer la migration
```bash
aws ecs run-task --cluster my-cluster --task-definition migration-task --launch-type EC2
```

ğŸ‘‰ Cette tÃ¢che exÃ©cute :  
- `scriptjson.py`  
- `scriptxls1.py`  
- `scriptxls2.py`  
- `pytest test_migration.py`  

et supprime les fichiers pickle en sortie.

---

### 5. Logs & monitoring
- Les logs MongoDB â†’ CloudWatch Logs group `/ecs/mongodb`
- Les logs migration â†’ `/ecs/migration-task`



---

## ğŸ” Test dâ€™accÃ¨s Ã  MongoDB via SSH

Le projet inclut un script `test_mongo.py` permettant de calculer le temps d'accÃ¨s Ã  MongoDB sur une instance EC2 distante en utilisant une **clÃ© SSH**.

### 1. PrÃ©-requis
- Instance **EC2** avec MongoDB (`mongo:latest`) en cours dâ€™exÃ©cution  
- Une **clÃ© SSH privÃ©e** valide (`.pem`) associÃ©e Ã  lâ€™instance  
- Port **22** ouvert dans le **Security Group**  

### 2. ParamÃ¨tres du script
- `user` â†’ utilisateur SSH (par dÃ©faut : `ec2-user`)  
- `key_path` â†’ chemin vers la clÃ© privÃ©e (par dÃ©faut : `keyprojet7.pem`)  
- Le script demande lâ€™**IP publique** de lâ€™instance EC2 au lancement.

### 3. ExÃ©cution
```bash
python migration/test_mongo.py
```

Exemple :
```
 Entrez l'adresse IP publique de l'instance EC2 : 3.250.xxx.xxx
```

### 4. Fonctionnement
1. Connexion SSH Ã  lâ€™instance avec la clÃ©  
2. DÃ©tection du conteneur `mongo:latest`  
3. ExÃ©cution dâ€™une requÃªte dâ€™agrÃ©gation sur la base `weather` :
   - Filtre : `dh_utc >= 2024-01-01`, `pluie_1h` non nul, `temperature <= 35`  
   - AgrÃ©gation par `station_name`  
   - Retourne : nombre de mesures, moyenne pluie, min/max tempÃ©rature  

### 5. Exemple de sortie
```
----  OUTPUT ----
[
  {
    "_id": "La Madeleine",
    "total_mesures": 140,
    "moyenne_pluie": 2.15,
    "min_temperature": 4,
    "max_temperature": 28
  },
  {
    "_id": "Ichtegem",
    "total_mesures": 120,
    "moyenne_pluie": 1.87,
    "min_temperature": 2,
    "max_temperature": 30
  }
]

â± Temps total d'accÃ¨s Ã  MongoDB : 3.42 secondes
```

---

## ğŸ“Š SchÃ©ma dâ€™architecture

```mermaid
flowchart TB
  subgraph ECS Cluster
    M1["Mongo1 Task (27017)"]
    M2["Mongo2 Task (27017)"]
    MA["Mongo Arbiter Task (27018)"]
    MIG["Migration Task (scripts + tests)"]
  end

  Airbyte["Airbyte Sources"] --> S3["AWS S3 (weather-data-pipeline)"]
  S3 --> MIG
  MIG --> M1
  MIG --> M2
  MIG --> MA
  M1 <--> M2
  M1 <--> MA
  M2 <--> MA
```
